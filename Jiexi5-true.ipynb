{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad402f19-c6bf-4ae8-a9f4-a261d7ee689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the adapted code base\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f2f9bd-5829-408b-a7ab-7e499574284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in positive and negative sample data\n",
    "z = pd.read_csv(r'D:/LSM/1JieXi2/1true/z.csv')\n",
    "f = pd.read_csv(r'D:/LSM/1JieXi2/1true/f.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973c5a3-2427-4392-baf0-d92683783698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Set labels\"\n",
    "z['Class'] = '1'\n",
    "f['Class'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f8ac2-5c82-4945-961d-b10a8bb1fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in positive and negative sample data\n",
    "zon = pd.read_csv(r'D:/LSM/1JieXi2/1test/zon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a94f50-825b-44d6-997a-1e07136ff830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename each feature value\n",
    "column_mapping = {\n",
    "    'DEM': 'Elevation',\n",
    "    'Slope': 'Slope',\n",
    "    'Aspect': 'Aspect',\n",
    "    'JXtwi': 'TWI',\n",
    "    'RDLS': 'Topographic relief',\n",
    "    'ys': 'Strata',\n",
    "    'TPI': 'Slope position',\n",
    "    'curvature': 'Slope curvature',\n",
    "    'landcover': 'Land cover',\n",
    "    'NDVI2': 'NDVI',\n",
    "    'Driver': 'Distance to river',\n",
    "    'rainfallzh': 'Accumulated rainfall'\n",
    "}\n",
    "\n",
    "z.rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be98ea1-bbfe-4e6a-9c20-74d98100f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename each feature value\n",
    "column_mapping = {\n",
    "    'DEM': 'Elevation',\n",
    "    'Slope': 'Slope',\n",
    "    'Aspect': 'Aspect',\n",
    "    'JXtwi': 'TWI',\n",
    "    'RDLS': 'Topographic relief',\n",
    "    'ys': 'Strata',\n",
    "    'TPI': 'Slope position',\n",
    "    'curvature': 'Slope curvature',\n",
    "    'landcover': 'Land cover',\n",
    "    'NDVI2': 'NDVI',\n",
    "    'Driver': 'Distance to river',\n",
    "    'rainfallzh': 'Accumulated rainfall'\n",
    "}\n",
    "\n",
    "f.rename(columns=column_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856ec7a-a3aa-465f-9042-4b9dda8fcf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear missing values\n",
    "is_minus_9999 = (f == -9999)\n",
    "\n",
    "minus_9999_count = is_minus_9999.sum()\n",
    "\n",
    "print(minus_9999_count)\n",
    "\n",
    "for column in f.columns:\n",
    "    if minus_9999_count[column] > 0:\n",
    "        print(f\"Column: {column} has {minus_9999_count[column]} occurrences of -9999\")\n",
    "        print(f[is_minus_9999[column]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706293c7-69e0-4442-8af5-072cc83eb88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear missing values\n",
    "is_minus_9999 = (z == -9999)\n",
    "\n",
    "minus_9999_count = is_minus_9999.sum()\n",
    "\n",
    "print(minus_9999_count)\n",
    "\n",
    "for column in z.columns:\n",
    "    if minus_9999_count[column] > 0:\n",
    "        print(f\"Column: {column} has {minus_9999_count[column]} occurrences of -9999\")\n",
    "        print(z[is_minus_9999[column]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39fd2cc-6d02-4c0a-91f7-24cb56df1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Be clear about the null value data of the test file\n",
    "f = f.replace(-9999, pd.NA).dropna()\n",
    "zon = pd.concat([f, z], ignore_index=True)\n",
    "zon.to_csv(r'D:/LSM/1JieXi2/1true/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080d9d6-c6ac-4fdd-bd8b-0d71ab438b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90419a1b-08c1-403d-8974-97ce6e81f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in positive and negative sample data\n",
    "train = pd.read_csv(r'D:/LSM/1JieXi2/1true/train.csv')\n",
    "test = pd.read_csv(r'D:/LSM/1JieXi2/1true/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee33026-3989-45c6-9f5b-70a90a45a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the test set proportionally\n",
    "#Be clear about the null value data of the test file\n",
    "train = train.drop(train.columns[0], axis=1)\n",
    "test = test.drop(test.columns[0], axis=1)\n",
    "test=test.iloc[0:20000000,0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f1361-1eac-42e0-8b09-f878fb4581f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b0b3d-852f-4d6a-b583-5400d107b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the sample set proportionally\n",
    "train,test=train_test_split(train,test_size=0.3,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e550d4-c2e5-4a09-8ccf-1e957f9e0470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the labeled and feature data\n",
    "y_train = train['Class'];\n",
    "X_train = train.drop(labels=['Class'], axis=1, level=None)\n",
    "\n",
    "y_test = test['Class'];\n",
    "X_test = test.drop(labels=['Class'], axis=1, level=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993659da-a6af-47c0-a762-39e507ea22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set an optimization time of 300 seconds for automatic optimization\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 300,  \n",
    "    \"metric\":  'roc_auc', \n",
    "    \"task\": 'classification', \n",
    "    \"estimator_list\": ['extra_tree'],\n",
    "    \"log_file_name\": 'class.log', \n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train, y_train=y_train,**settings)\n",
    "print(automl.predict_proba(X_train).shape)\n",
    "# Export the best model\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873131fc-e250-4352-8a4a-c74c85035a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View historical records\n",
    "automl.config_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca83784e-4afd-407a-9540-2e7353630464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the specific values of the evaluation indicators\n",
    "print('Best ML leaner:', automl.best_estimator)\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827cacb-aded-471a-8f70-30eca4108ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test test data\n",
    "\n",
    "y_pred5 = automl.predict(X_test)\n",
    "print('Predicted labels', y_pred5)\n",
    "print('True labels', y_test)\n",
    "y_pred_proba5 = automl.predict_proba(X_test)[:,1]\n",
    "gl5 =automl.predict_proba(X_test)\n",
    "gl5 = pd.DataFrame(gl5)\n",
    "gl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6e26b-961b-4de3-879d-52fabd03dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the values of the three evaluation indicators\n",
    "from flaml.ml import sklearn_metric_loss_score\n",
    "print('accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred5, y_test))\n",
    "print('roc_auc', '=', 1 - sklearn_metric_loss_score('roc_auc', y_pred_proba5, y_test))\n",
    "print('log_loss', '=', sklearn_metric_loss_score('log_loss', y_pred_proba5, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543080ab-b249-4771-8f9f-71d08ced521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,recall_score,accuracy_score,f1_score\n",
    "print(classification_report(y_test,y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b966dd0a-4083-42cb-a891-6fdbb9f5d16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw the ROC curve of a single model\n",
    "from sklearn import  metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "plt.figure(figsize = (5,5) ,dpi = 300)\n",
    "fpr,tpr,th=roc_curve(y_test,y_pred_proba5)\n",
    "plt.plot(fpr,tpr, color='blue', label='ET_Best_AUC={:.4f}'.format(metrics.roc_auc_score(y_test,y_pred_proba5))) # roc curve\n",
    "plt.legend()\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446db51-915c-4610-96e5-ec8800e58393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record the optimization process\n",
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=settings['log_file_name'], time_budget=300)\n",
    "for config in config_history:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35816af3-6387-430c-beb5-9912ad29411b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw the optimization curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "plt.figure(figsize = (5,5) ,dpi = 300)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64a58d-8631-4788-a76a-5e2b86645251",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree=automl.model.estimator#Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ae439-1688-4c06-95c3-84b2195fe60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dbe628-da79-4323-8bcd-3ab1fe661b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set an optimization time of 600 seconds for automatic optimization\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "## 参数设定\n",
    "settings = {\n",
    "    \"time_budget\": 600,  \n",
    "    \"metric\":  'roc_auc',\n",
    "    \"estimator_list\": ['extra_tree'],\n",
    "    \"log_file_name\": 'class.log', \n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train, y_train=y_train,**settings)\n",
    "print(automl.predict_proba(X_train).shape)\n",
    "# Export the best model\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463530be-ef3f-45a4-a8e6-8af83315665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View historical records\n",
    "automl.config_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58734e1-5831-4728-8160-68143811126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the specific values of the evaluation indicators\n",
    "print('Best ML leaner:', automl.best_estimator)\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65aa419-5195-4e8a-a9e7-12dfd10d0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test test data\n",
    "\n",
    "y_pred5 = automl.predict(X_test)\n",
    "print('Predicted labels', y_pred5)\n",
    "print('True labels', y_test)\n",
    "y_pred_proba5 = automl.predict_proba(X_test)[:,1]\n",
    "gl5 =automl.predict_proba(X_test)\n",
    "gl5 = pd.DataFrame(gl5)\n",
    "gl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d911f5b9-c197-4d84-88e0-d26c26048327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the values of the three evaluation indicators\n",
    "from flaml.ml import sklearn_metric_loss_score\n",
    "print('accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred5, y_test))\n",
    "print('roc_auc', '=', 1 - sklearn_metric_loss_score('roc_auc', y_pred_proba5, y_test))\n",
    "print('log_loss', '=', sklearn_metric_loss_score('log_loss', y_pred_proba5, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a033d75-24d5-4483-a175-0c034d84d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,recall_score,accuracy_score,f1_score\n",
    "print(classification_report(y_test,y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14490080-a027-47b5-b986-c74e97e93169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw the ROC curve of a single model\n",
    "from sklearn import  metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "plt.figure(figsize = (5,5) ,dpi = 300)\n",
    "fpr,tpr,th=roc_curve(y_test,y_pred_proba5)\n",
    "plt.plot(fpr,tpr, color='orange', label='ET_Best_AUC={:.4f}'.format(metrics.roc_auc_score(y_test,y_pred_proba5))) # roc curve\n",
    "plt.legend()\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc8b7f0-a5e8-4440-a4b0-147e5c2694d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record the optimization process\n",
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=settings['log_file_name'], time_budget=300)\n",
    "for config in config_history:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9927aa-ef81-4e36-9c0f-89972655a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw the optimization curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "plt.figure(figsize = (5,5) ,dpi = 300)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4c62d-7c01-4c31-a6df-7ec5050e53fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree=automl.model.estimator#Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36efea-2c5f-40b2-98b5-88f87480d651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8b1739-b7f3-4a8a-a811-1fbcb0ae09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set an optimization time of 1800 seconds for automatic optimization\n",
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "\n",
    "settings = {\n",
    "    \"time_budget\": 1800, \n",
    "    \"metric\":  'roc_auc',\n",
    "    \"estimator_list\": ['extra_tree'],\n",
    "    \"log_file_name\": 'class.log',\n",
    "}\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train, y_train=y_train,**settings)\n",
    "print(automl.predict_proba(X_train).shape)\n",
    "# Export the best model\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e4e35-ac2a-4b9d-894c-bb187f78816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View historical records\n",
    "automl.config_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf7bf8-4eff-4da0-9810-75690c2275cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the specific values of the evaluation indicators\n",
    "print('Best ML leaner:', automl.best_estimator)\n",
    "print('Best hyperparmeter config:', automl.best_config)\n",
    "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
    "print(automl.model.estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b7166-62e4-4dbe-96ca-1db30306e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test test data\n",
    "\n",
    "y_pred5 = automl.predict(X_test)\n",
    "print('Predicted labels', y_pred5)\n",
    "print('True labels', y_test)\n",
    "y_pred_proba5 = automl.predict_proba(X_test)[:,1]\n",
    "gl5 =automl.predict_proba(X_test)\n",
    "gl5 = pd.DataFrame(gl5)\n",
    "gl5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312dbf9-0af6-48a0-9f12-ff8cc66294ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the values of the three evaluation indicators\n",
    "from flaml.ml import sklearn_metric_loss_score\n",
    "print('accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred5, y_test))\n",
    "print('roc_auc', '=', 1 - sklearn_metric_loss_score('roc_auc', y_pred_proba5, y_test))\n",
    "print('log_loss', '=', sklearn_metric_loss_score('log_loss', y_pred_proba5, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520982d-a4c6-4bf0-b18e-78cacd6f456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,recall_score,accuracy_score,f1_score\n",
    "print(classification_report(y_test,y_pred5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476b32b-4aac-45b2-8532-51e8ca73f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw the ROC curve of a single model\n",
    "from sklearn import  metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "plt.figure(figsize = (5,5) ,dpi = 300)\n",
    "fpr,tpr,th=roc_curve(y_test,y_pred_proba5)\n",
    "plt.plot(fpr,tpr, color='orange', label='ET_Best_AUC={:.4f}'.format(metrics.roc_auc_score(y_test,y_pred_proba5))) # roc curve\n",
    "plt.legend()\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1bd96-6fe1-43d7-8c82-3940437d2c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Record the optimization process\n",
    "from flaml.data import get_output_from_log\n",
    "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
    "    get_output_from_log(filename=settings['log_file_name'], time_budget=300)\n",
    "for config in config_history:\n",
    "    print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b72162b-3b05-46a4-8c78-e667f59e9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw the optimization curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Times New Roman']\n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "plt.figure(figsize = (5,5) ,dpi = 300)\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Wall Clock Time (s)')\n",
    "plt.ylabel('Validation Accuracy') \n",
    "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
    "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c9bf55-274e-4346-9566-109b64311fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d793bcc4-4324-409f-a65b-c4d5ed68549d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b73b47-6530-422e-8d0c-580863a0fbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
